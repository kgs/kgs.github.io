<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Kamil Gorlo]]></title>
  <link href="http://www.kamilgorlo.com/atom.xml" rel="self"/>
  <link href="http://www.kamilgorlo.com/"/>
  <updated>2017-09-02T14:30:47+02:00</updated>
  <id>http://www.kamilgorlo.com/</id>
  <author>
    <name><![CDATA[Kamil Gorlo]]></name>
    <email><![CDATA[kgorlo+blog@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Geospatial analytics on Hadoop]]></title>
    <link href="http://www.kamilgorlo.com/2016/01/29/geospatial-analytics-on-hadoop/"/>
    <updated>2016-01-29T12:32:01+01:00</updated>
    <id>http://www.kamilgorlo.com/2016/01/29/geospatial-analytics-on-hadoop</id>
    <content type="html"><![CDATA[<p>Few months ago I was working on a project with a lot of geospatial data. Data was stored in HDFS, easily accessible through Hive. One of the tasks was to analyze this data and first step was to join two datasets on columns which were geographical coordinates. I wanted some easy and efficient solution. But here is the problem - there is very little support for this kind of operations in Hadoop world.</p>

<!-- more -->


<h3>Problem</h3>

<p>Ok, so what&rsquo;s the problem actually? Let&rsquo;s say we have two datasets (represented as Hive tables). First one is very large set of geo-tagged tweets. Second one is city/place geographic boundaries. We want to match them - for every tweet we want to know it&rsquo;s location name.</p>

<p>Here are the tables (coordinates are given in simple <a href="https://en.wikipedia.org/wiki/Well-known_text">WKT format</a>):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>+-----------+------------------+---------------------------------------------+
</span><span class='line'>| tweets.id |  tweets.content  |  tweets.location_wkt                        |
</span><span class='line'>+-----------+------------------+---------------------------------------------+
</span><span class='line'>| 11        | Hi there!        | POINT(21.08448028564453 52.245122234020435) |
</span><span class='line'>| 42        | Wow, great trip! | POINT(22.928466796875 54.12185996058409)    |
</span><span class='line'>| 128       | Happy :)         | POINT(13.833160400390625 46.38046653471246) |
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>+-----------+-----------------+-----------------------------------------------------+
</span><span class='line'>| places.id |  places.name    |  places.boundaries_wkt                              |
</span><span class='line'>+-----------+-----------------+-----------------------------------------------------+
</span><span class='line'>| 65        | Warsaw          | POLYGON((20.76965332 52.356842,21.25305 52.3567 ... |
</span><span class='line'>| 88        | Suwałki         | POLYGON((22.890014 54.12829,22.96142 54.12829 ...   |
</span><span class='line'>| 89        | Triglav         | POLYGON((13.820114 46.383597,13.846206 46.38359 ... |
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>So how to do it in Hive or Spark? Without any additional libraries or tricks we can simply do <strong>cross join</strong>, which means: compare every element from first dataset with element from the second one and then decide (using some user defined function) if there is a match.</p>

<p>But this solution has two major drawbacks:</p>

<ul>
<li>it is super slow</li>
<li>we need to write some code (UDFs) which will operate on coordinates (checks if point is in polygon, etc.)</li>
</ul>


<p>For sure there must be a better way!</p>

<h3>What are the options?</h3>

<p>There are few libraries which could help us with this task, but some of them give us only nice API (GIS Tools, Magellan) where other can do spatial joins effectively (SpatialSpark). Let&rsquo;s look at them one by one!</p>

<h3>Esri GIS Tools for Hadoop</h3>

<p>People from Esri (international company which provides Geographic Information System software) developed and open sourced <a href="https://esri.github.io/gis-tools-for-hadoop/">GIS Tools for Hadoop</a>. This toolkit contains few elements, but two most important ones are:</p>

<ul>
<li><a href="https://github.com/Esri/geometry-api-java">Esri Geometry API for JAVA</a> - it includes geometry objects, spatial operations and indexing. It can be used in standalone programs or MapReduce/Spark jobs.</li>
<li><a href="https://github.com/Esri/spatial-framework-for-hadoop">Spatial Framework for Hadoop</a> - this library includes user defined functions (UDF) that extend Hive to make spatial operations more user-friendly, internally it uses Esri Geometry API.</li>
</ul>


<p>To install this toolkit you have to simply add jars to Hive classpath and then register needed UDFs. You can find more detailed tutorial <a href="https://github.com/Esri/gis-tools-for-hadoop/tree/master/samples/point-in-polygon-aggregation-hive">here</a>.</p>

<p>Finally you will be able to run Hive query like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">places</span><span class="p">,</span> <span class="n">tweets</span>
</span><span class='line'>    <span class="k">WHERE</span> <span class="n">ST_Intersects</span><span class="p">(</span>
</span><span class='line'>               <span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">places</span><span class="p">.</span><span class="n">boundaries_wkt</span><span class="p">),</span>
</span><span class='line'>               <span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">tweets</span><span class="p">.</span><span class="n">location_wkt</span><span class="p">)</span>
</span><span class='line'>          <span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>If you know <a href="http://postgis.net/">Postgis</a> (GIS extension for PostgreSQL) this will look very familiar to you, because syntax is similar. Unfortunately these kind of queries are very inefficient in Hive. Hive will do cross join and it means that for big datasets computations will last for unacceptable amount of time.</p>

<h4>Spatial binning</h4>

<p>There is small trick which can help a bit with efficiency problem when doing spatial joins. It&rsquo;s called spatial binning. The idea is to divide our space with points and polygons to numbered rectangular blocks. Then, for every object (like point or polygon) we assign corresponding block number to it.</p>

<p>Here is (hopefully) helpful image:</p>

<p><img class="center" src="http://www.kamilgorlo.com/images/binning.png"></p>

<p>In the above example, space was divided into 8 blocks, there are some empty blocks and some with many points. For example there are 5 points which will get number 4 as their <strong>BIN ID</strong>.</p>

<p>Going back to our example with tweets (represented as points) and places (represented as polygons) we can assign BIN IDs to both of them and then join them block by block, calling UDFs only for objects with the same BIN ID. It will be more efficient because we will only do cross joins for significantly smaller sets (one block), but many of them (as many as total number of blocks).</p>

<p>Of course, there are some corner cases (like borders of blocks), but general idea is as explained. If you want to read more about this technique, please visit <a href="https://github.com/Esri/gis-tools-for-hadoop/wiki/Aggregating-CSV-Data-%28Spatial-Binning%29">Esri Wiki</a>.</p>

<h3>Magellan</h3>

<p>Second solution I&rsquo;d like to show you is based on Apache Spark - more powerful (but also a bit more complicated) tool than Apache Hive.</p>

<p>Magellan is open source library for geospatial analytics that uses Spark as underlying engine. Hortonworks published blog post about it <a href="http://hortonworks.com/blog/magellan-geospatial-analytics-in-spark/">here</a> and as far as I understand this library was created by one of the company&rsquo;s engineers.</p>

<p>It is in very early stage of development and as of this date it gives us only nice API and unfortunately not so efficient algorithms for spatial joins.</p>

<p>Here is sample code in Spark (using Scala) to do spatial join using <em>intersects</em> predicate:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="c1">// points and polygons are DataFrames of types magellan.{Point, Polygon}</span>
</span><span class='line'><span class="n">points</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">polygons</span><span class="o">).</span><span class="n">where</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;point&quot;</span> <span class="n">intersects</span> <span class="n">$</span><span class="s">&quot;polygon&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>It is definitely library to watch, but as for now it&rsquo;s not so useful in my opinion, mainly because it&rsquo;s lacking features. If you want to know more, please visit Magellan <a href="https://github.com/harsha2010/magellan">github page</a>.</p>

<h3>SpatialSpark</h3>

<p>Third solution and also my favourite one (maybe because I contributed to it a bit ;)) is <a href="http://simin.me/projects/spatialspark/">SpatialSpark</a>. It&rsquo;s another library that is using Apache Spark as underlying engine. For low-level spatial functions and data structures (like indexes) it is using great and well tested <a href="http://tsusiatsoftware.net/jts/main.html">JTS</a> library.</p>

<p>It&rsquo;s selling feature is that it can do spatial joins efficiently. It supports two kind of joins:</p>

<ul>
<li><strong>broadcast spatial join</strong> - it&rsquo;s designed for joining big dataset with smaller one efficiently. Smaller data set is converted to index (R-tree) and kept in memory. Algorithm simply iterates (in distributed way) over big dataset and queries index from the other set efficiently.</li>
<li><strong>partitioned spatial join</strong> - it&rsquo;s designed for joining two big datasets and uses similar idea to binning, but it&rsquo;s more complicated and more efficient. Sets are divided into small pieces (you can choose what algorithm could be responsible for this operation - there are few implemented to make splits as equal as possible depending on data characteristics) and then each small piece is processed individually (using R-trees).</li>
</ul>


<p>Here is sample Spark code snippet to do broadcast spatial join for our case with tweets and places:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="c1">// create RDD with pairs (id, location_geometry) for tweets</span>
</span><span class='line'><span class="k">val</span> <span class="n">leftGeometryById</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Geometry</span><span class="o">)]</span> <span class="k">=</span>
</span><span class='line'>  <span class="n">tweets</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">r</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">toLong</span><span class="o">,</span> <span class="k">new</span> <span class="nc">WKTReader</span><span class="o">().</span><span class="n">read</span><span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">location_wkt</span><span class="o">)))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// right geometry (places) has to be relatively small for broadcast join</span>
</span><span class='line'><span class="k">val</span> <span class="n">rightGeometryById</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Geometry</span><span class="o">)]</span> <span class="k">=</span>
</span><span class='line'>  <span class="n">places</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">r</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">toLong</span><span class="o">,</span> <span class="k">new</span> <span class="nc">WKTReader</span><span class="o">().</span><span class="n">read</span><span class="o">(</span><span class="n">r</span><span class="o">.</span><span class="n">boundaries_wkt</span><span class="o">)))</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// we get matching ids from tweets and places</span>
</span><span class='line'><span class="k">val</span> <span class="n">matchedIdPairs</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">Long</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span>
</span><span class='line'>  <span class="nc">BroadcastSpatialJoin</span><span class="o">(</span><span class="n">sparkContext</span><span class="o">,</span> <span class="n">leftGeometryById</span><span class="o">,</span> <span class="n">rightGeometryById</span><span class="o">,</span>
</span><span class='line'>                       <span class="nc">SpatialOperator</span><span class="o">.</span><span class="nc">Intersects</span><span class="o">,</span> <span class="mf">0.0</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Unfortunately there are also drawbacks. API is not so clean and easy to use. You have to use classes as shown in example above or use command line tools that expect data in exactly one format (more details on <a href="https://github.com/syoummer/SpatialSpark">github page</a>). Even bigger problem is that development of SpatialSpark is not so active. Hopefully it will change in future.</p>

<h3>Other options</h3>

<p>If you can and want to keep data in some other systems than Hadoop there are few possibilities to do spatial joins. Of course not all of them have the same set of features, but all of them implement some kind of geospatial search that could be useful when dealing with geographic data.</p>

<p>Here are the links:</p>

<ul>
<li><a href="https://github.com/Stratio/cassandra-lucene-index">Cassandra with Lucene index</a> - you can keep data in Cassandra and use secondary index that integrates Lucene features (geospatial search is one of many)</li>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/geohashes.html">Elasticsearch (with Geohashes)</a> - geohashes are a way of encoding latitude and longitude to string, you can keep and query them with Elasticsearch</li>
<li><a href="http://www.geomesa.org/">GeoMesa</a> - it&rsquo;s whole geospatial distributed database built on top of Apache Accumulo</li>
<li><a href="https://ngageoint.github.io/geowave/">GeoWave</a> - very similar to GeoMesa, but a bit newer</li>
</ul>


<h3>Summary</h3>

<p>As you can probably see now, there is no big choice in terms of spatial joins when we have our data in Hadoop. If you want to do things efficiently then <a href="http://simin.me/projects/spatialspark/">SpatialSpark</a> is the only option IMHO. If you want something easier to use then <a href="https://esri.github.io/gis-tools-for-hadoop/">Esri GIS Tools for Hadoop</a> is the way to go, but unfortunately this only makes sense for really small datasets.</p>

<p>That&rsquo;s all! Hopefully you&rsquo;ve enjoyed this post. Feel free to comment below if you have any questions or suggestions.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why blog?]]></title>
    <link href="http://www.kamilgorlo.com/2014/08/16/why-blog/"/>
    <updated>2014-08-16T16:45:55+02:00</updated>
    <id>http://www.kamilgorlo.com/2014/08/16/why-blog</id>
    <content type="html"><![CDATA[<p>OK, this is awkward. My first blog post. I never thought that this moment would come, but somehow I am here. Let&rsquo;s see how this gonna work. Do you wonder why I started this site? If yes - read on!</p>

<!-- more -->


<p>This is one of the ideas that you have, but because of your lack of time (or whatever) you decide to give up. That was also my case. I&rsquo;ve planned to create my own blog for quite some time and now finally decided to give it a go. Worst part is now over - I&rsquo;ve started ;) Even if frequency of posts will be poor, I think it is still worth it because of few reasons. I&rsquo;ll try to explain them in next paragraph.</p>

<h3>Why it started</h3>

<ul>
<li><p>I&rsquo;ve had very inspiring episode in my professional career. I was leader of laboratory group for “Programming Languages and Tools” course at University of Warsaw. It was great (very tiring when mixed with full time work, but great). When I was teaching students different aspects of C++ programming I think I&rsquo;ve learned even more myself. Teaching is the best learning method. Let&rsquo;s not forget about feedback from others (in this case - students) which is priceless.</p>

<p>I hope you already know what I&rsquo;m trying to tell. Writing about recently learned <em>thing</em> will be a great way of memorizing and understanding it. Blog is also much less absorbing than teaching classes at university, of course :)</p></li>
<li><p>I trust that somehow I will help other people solve problems I&rsquo;ve spent time on. Without all these tech blogs and especially <a href="http://stackoverflow.com/">StackOverflow</a> my life would be so much harder. This is my try to give back to community.</p></li>
<li>Last, but not least - self branding. That&rsquo;s another motivation to start blogging and I&rsquo;ve learned about it recently from this great post: <a href="http://chase-seibert.github.io/blog/2014/08/01/why-blogging.html">&ldquo;Why software engineers should maintain a blog&rdquo;</a>. Go and read it, you will not regret.</li>
</ul>


<h3>Real reason?</h3>

<p>OK, let&rsquo;s make things clear. I&rsquo;m tech guy. What is the most interesting part of blogging for me? Technology of course! In the last few weeks, thanks to Tomasz Dziurko and his <a href="http://tomaszdziurko.pl">blog</a>, I&rsquo;ve discovered <a href="http://octopress.org/">Octopress</a> - a blogging platform for hackers. And then I&rsquo;ve finally felt it - this is it! Idea of writing blog as markdown pages (where you can use versioning system, like Git for example) and then generating static HTML was brilliant. I do not even need own hosting because of excellent <a href="https://pages.github.com/">GitHub Pages</a>. Templates are clean, focused on readability and you can easily paste source code (which looks great, does not break anything , even on mobile devices).</p>

<p>Of course, before choosing Octopress, I&rsquo;ve made a research (I love doing research - who doesn&rsquo;t?). I have considered using <a href="http://jekyllrb.com/">Jekyll</a> alone or with <a href="http://getpoole.com/">Poole</a>. Poole is really nice if you want to start with even simpler blog, I highly recommend it. It comes with two additional, polished, responsive templates (<a href="http://hyde.getpoole.com/">Hyde</a> and <a href="http://lanyon.getpoole.com/">Lanyon</a>) and it&rsquo;s very easy to setup with GitHub (you can find very good blog post about it <a href="http://joshualande.com/jekyll-github-pages-poole/">here</a>). Nevertheless, I&rsquo;ve decided to stick with Octopress which gives me a bit higher abstraction layer over Jekyll and comes with many plugins for categories, syntax highlighting and more.</p>

<h3>Final words</h3>

<p>My writing skills are not perfect - I know it. What&rsquo;s even worse, I&rsquo;ve decided to write in English which is not my native language. I know that sometimes it will be painful for you to read my posts, because of grammar errors, punctuation errors or nonsense phrases. I&rsquo;ll try to do my best to eliminate them (that&rsquo;s one of the reasons I&rsquo;ve started writing!), but what is more important for me is to write something, share ideas and do not worry about not-so-perfect form.</p>

<p>OK, I think that&rsquo;s it for beginning. If you want to read more about me (or more about this blog), please visit <a href="http://www.kamilgorlo.com/about">about</a> page.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
</feed>
